\relax 
\citation{Benesty2009}
\citation{Fant1981}
\citation{Aryal2016}
\citation{Taguchi}
\citation{Liu2018}
\citation{Hochreiter1997}
\citation{Gonzalez2017}
\citation{Richmond2011}
\citation{Wrench1999}
\citation{Rudzicz2012}
\citation{Halpern2019}
\citation{Gonzalez2016}
\@writefile{toc}{\contentsline {section}{\numberline {1} Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2} Method}{1}}
\newlabel{section:method}{{2}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1} Dataset preprocessing}{1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1} Electrode preprocessing}{1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2} Speech data processing}{1}}
\citation{Morise2016}
\citation{pysptk}
\citation{Gonzalez2017}
\citation{Chen1997}
\citation{Kawahara2006}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Articulatory information recorded in datasets\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:electrodes}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The visualisation of electrode locations for 300 samples from the MNGU0 dataset at their initial position. The drawing is only indicative of real positions.\relax }}{2}}
\newlabel{fig:electrodes}{{1}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3} Sampling}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Thresholded Sobel mask of activations indicates that a boundary phenomena is learned by the neural network. \relax }}{2}}
\newlabel{fig:mask}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Red dashed line indicates training-only setup, and blue dotted lines indicate inference for speech synthesis. Best viewed in colour.\relax }}{2}}
\newlabel{fig:structure}{{3}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4} Fundamental frequency interpolation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2} Synthesis setup}{2}}
\citation{Taguchi}
\citation{Liu2018}
\citation{Gonzalez2017}
\citation{Kingma2015}
\citation{Taguchi}
\citation{Wu2016}
\citation{Kubichek1993}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of preprocessing techniques of some previous studies. In the case of EMA data, there is a clear consensus of 40 MFCC channels.\relax }}{3}}
\newlabel{tab:example}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3} Neural network design}{3}}
\newlabel{section:nnexperiment}{{2.3}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance of speaker-independent articulatory to acoustic neural network for 10-fold cross-validation with 95 \% confidence intervals. In the TORGO dataset, different recording sessions were kept in different datasets. \relax }}{3}}
\newlabel{tab:all_data}{{3}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Comparison of different training methods used in previous publications with the results of the pilot study using held-out validation. The method described in the paper of Gonzalez performed best.\relax }}{3}}
\newlabel{tab:architectures}{{4}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4} Articulatory space modification}{3}}
\newlabel{section:speech}{{2.4}{3}}
\citation{Jozefowicz2015}
\citation{Palaz2015}
\citation{Selvaraju2017}
\citation{Speech2019}
\bibstyle{IEEEtran}
\bibdata{paper1}
\bibcite{Benesty2009}{1}
\bibcite{Fant1981}{2}
\bibcite{Aryal2016}{3}
\bibcite{Taguchi}{4}
\@writefile{toc}{\contentsline {section}{\numberline {3} Results and discussion}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1} Pilot study}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2} Prediction of MFCC values}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3} What do these neural networks learn?}{4}}
\newlabel{section:visualisation}{{3.3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4} The current limitations of the synthesis}{4}}
\newlabel{section:limitations}{{3.4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5} Pathological speech examples}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Partial data retraining shows that adding more data would decrease loss\relax }}{4}}
\newlabel{learning_curve}{{4}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4} Conclusions}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {5} Acknowledgements}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {6} References}{4}}
\bibcite{Liu2018}{5}
\bibcite{Hochreiter1997}{6}
\bibcite{Gonzalez2017}{7}
\bibcite{Richmond2011}{8}
\bibcite{Wrench1999}{9}
\bibcite{Rudzicz2012}{10}
\bibcite{Halpern2019}{11}
\bibcite{Gonzalez2016}{12}
\bibcite{Morise2016}{13}
\bibcite{pysptk}{14}
\bibcite{Chen1997}{15}
\bibcite{Kawahara2006}{16}
\bibcite{Kingma2015}{17}
\bibcite{Wu2016}{18}
\bibcite{Kubichek1993}{19}
\bibcite{Jozefowicz2015}{20}
\bibcite{Palaz2015}{21}
\bibcite{Selvaraju2017}{22}
\bibcite{Speech2019}{23}
