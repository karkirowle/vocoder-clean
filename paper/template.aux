\relax 
\citation{Benesty2009}
\citation{Fant1981}
\citation{Aryal2016}
\citation{Taguchi}
\citation{Liu2018}
\citation{Hochreiter1997}
\citation{Gonzalez2017}
\citation{Richmond2011}
\citation{Rudzicz2012}
\citation{Halpern2019}
\citation{Gonzalez2016}
\citation{Morise2016}
\citation{pysptk}
\@writefile{toc}{\contentsline {section}{\numberline {1} Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2} Method}{1}}
\newlabel{section:method}{{2}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1} Dataset preprocessing}{1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1} Electrode preprocessing}{1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2} Speech data processing}{1}}
\citation{Gonzalez2017}
\citation{Chen1997}
\citation{Kawahara2006}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Articulatory information recorded in datasets\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:electrodes}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The visualisation of electrode locations for 300 samples from the MNGU0 dataset at their initial position.\relax }}{2}}
\newlabel{fig:electrodes}{{1}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3} Sampling}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Thresholded Prewitt mask of activations indicates that a boundary phenomena is learned by the neural network. Best viewed in zoom.\relax }}{2}}
\newlabel{fig:mask}{{2}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4} Fundamental frequency interpolation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2} Synthesis setup}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of preprocessing techniques\relax }}{2}}
\newlabel{tab:example}{{2}{2}}
\citation{Taguchi}
\citation{Liu2018}
\citation{Gonzalez2017}
\citation{Kingma2015}
\citation{Taguchi}
\citation{Wu2016}
\citation{Kubichek1993}
\citation{Jozefowicz2015}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Red dashed line indicates training-only setup, and blue dotted lines indicate inference for speech synthesis. Best viewed in colour.\relax }}{3}}
\newlabel{fig:structure}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3} Neural network design}{3}}
\newlabel{section:nnexperiment}{{2.3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1} An empirical look at previous architectures}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4} Articulatory space modification}{3}}
\newlabel{section:speech}{{2.4}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance of speaker-independent articulatory to acoustic neural network for 10-fold cross-validation with 95 \% confidence intervals. In the TORGO dataset, different recording sessions were kept in different datasets. \relax }}{3}}
\newlabel{tab:all_data}{{3}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Comparison of different training methods used in previous publications with the results of the pilot study using held-out validation. The method described in the paper of Gonzalez performed best.\relax }}{3}}
\newlabel{tab:architectures}{{4}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3} Results and discussion}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1} Pilot study}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2} Prediction of MFCC values}{3}}
\citation{Palaz2015}
\citation{Selvaraju2017}
\citation{Speech2019}
\bibstyle{IEEEtran}
\bibdata{paper1}
\bibcite{Benesty2009}{1}
\bibcite{Fant1981}{2}
\bibcite{Aryal2016}{3}
\bibcite{Taguchi}{4}
\bibcite{Liu2018}{5}
\bibcite{Hochreiter1997}{6}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Partial data retraining shows that adding more data would decrease loss\relax }}{4}}
\newlabel{learning_curve}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3} What do these neural networks learn?}{4}}
\newlabel{section:visualisation}{{3.3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4} The current limitations of the synthesis}{4}}
\newlabel{section:limitations}{{3.4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5} Pathological speech examples}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4} Conclusion}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {5} Acknowledgements}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {6} References}{4}}
\bibcite{Gonzalez2017}{7}
\bibcite{Richmond2011}{8}
\bibcite{Rudzicz2012}{9}
\bibcite{Halpern2019}{10}
\bibcite{Gonzalez2016}{11}
\bibcite{Morise2016}{12}
\bibcite{pysptk}{13}
\bibcite{Chen1997}{14}
\bibcite{Kawahara2006}{15}
\bibcite{Kingma2015}{16}
\bibcite{Wu2016}{17}
\bibcite{Kubichek1993}{18}
\bibcite{Jozefowicz2015}{19}
\bibcite{Palaz2015}{20}
\bibcite{Selvaraju2017}{21}
\bibcite{Speech2019}{22}
